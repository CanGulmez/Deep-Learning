{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras functional API\n",
    "\n",
    "In the functional API, you directly manipulate tensors, and you use layers as _functions_ that take tensors and return tensors (hence, the name _functional API_ )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdiction to functional API\n",
    "\n",
    "Let’s start with a minimal example that shows side by side a simple Sequential model and its equivalent in the functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The functional equivalent\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error tells, in essence, that _Keras_ couldn’t reach `input_1` from the provided output tensor.\n",
    "When it comes to compiling, training, or evaluating such an instance of `Model`, the API is the same as that of `Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 3s 21ms/step - loss: 42.8623\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 51.0456\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.6315\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 65.9072\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7182\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.3812\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4314\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.4778\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2652\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 110.3922\n",
      "32/32 [==============================] - 1s 3ms/step - loss: 117.6098\n",
      "117.60975646972656\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compiles the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# Generates dummy Numpy data to train on\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "# Trains the model for 10 epochs\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "# Evaluates the model\n",
    "score = model.evaluate(x_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-input models\n",
    "\n",
    "The functional API can be used to build models that have multiple inputs. Typically, such models at some point merge their different input branches using a layer that can combine several tensors: by adding them, concatenating them, and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A question-answering model\n",
    "\n",
    "A typical question-answering model has two inputs: a natural-language question and a text snippet (such as a news article) providing information to be used for answering the question. The model must then produce an answer: in the simplest possible setup, this is a one-word answer obtained via a softmax over some predefined vocabulary:\n",
    "\n",
    "<img src=\"./resources/question-answering-model.png\" alt=\"qa-model\" style=\"width: 300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the implementation with the _Keras_ functional API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           12416       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           3136        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          24500       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# The text input is a variable-length sequence of integers. Note that you can optionally name the inputs.\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "# Embeds the inputs into a sequence of vectors of size 64\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "# Encodes the vectors in a single vector via an LSTM\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# Same process (with different layer instances) for the question\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# Concatenates the encoded question and encoded text\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "# Adds a softmax classifier on top\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "# At model instantiation, you specify the two inputs and the output.\n",
    "model = Model([text_input, question_input], answer)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **how do you train this two-input model?** There are two possible APIs: you can **feed the model a list of Numpy arrays as inputs**, or you can **feed it a dictionary that maps input names to Numpy arrays**. Naturally, the latter option is available only if you give names to your inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 18s 327ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 3s 304ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 7s 203ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fcd77dfc10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# Generates dummy Numpy data\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "# Answers are one-hot encoded, not integers\n",
    "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "# Fitting using a list of inputs\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# Fitting using a dictionary of inputs (only if inputs are named)\n",
    "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-input models\n",
    "\n",
    "In the same way, you can use the functional API to build models with multiple outputs (or multiple _heads_ )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A three-outputs model\n",
    "\n",
    "A simple example is a network that attempts to simultaneously predict different properties of the data, such as a network that takes as input a series of social media posts from a single anonymous person and tries to predict attributes of that person, such as age, gender, and income level\n",
    "\n",
    "<img src=\"./resources/three-outputs-model.png\" alt=\"qa-model\" style=\"width: 300px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50000)  12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 128)    32000128    embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, None, 128)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    164096      max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    327936      conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32896       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 45,982,476\n",
      "Trainable params: 45,982,476\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# Note that the output layers are given names\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile with multiple losses\n",
    "\n",
    "Importantly, training such a model requires the ability to **specify different loss functions for different heads of the network**: for instance, age prediction is a scalar regression task, but gender prediction is a binary classification task, requiring a different training procedure. But because gradient descent requires you to minimize a _scalar_, you must **combine these losses into a single value** in order to train the model. The simplest way to combine different losses is to sum them all. In *Keras*, you can use either a list or a dictionary of losses in `compile` to specify different objects for different outputs; **the resulting loss values are summed into a global loss, which is minimized during training**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss=['mse', 'categorical_crossentropy', 'binary_crossentropy']\n",
    ")\n",
    "\n",
    "# Equivalent (possible only if you give names to the output layers)\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss={\n",
    "        'age': 'mse',\n",
    "        'income': 'categorical_crossentropy',\n",
    "        'gender': 'binary_crossentropy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss weighting\n",
    "\n",
    "Note that very **imbalanced loss contributions will cause the model representations to be optimized preferentially for the task with the largest individual loss**, at the expense of the other tasks. To remedy this, you can assign **different levels of importance** to the loss values in their contribution to the final loss. This is useful in particular if the losses' values use different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'], \n",
    "    loss_weights=[0.25, 1., 10.]\n",
    ")\n",
    "\n",
    "# Equivalent (possible only if you give names to the output layers)\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss={\n",
    "        'age': 'mse',\n",
    "        'income': 'categorical_crossentropy',\n",
    "        'gender': 'binary_crossentropy'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'age': 0.25,\n",
    "        'income': 1.,\n",
    "        'gender': 10.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feeding data to a multi-output model\n",
    "\n",
    "Much as in the case of multi-input models, you can pass Numpy data to the model for training either via a list of arrays or via a dictionary of arrays.\n",
    "\n",
    "```python\n",
    "# age_targets, income_targets, and gender_targets are assumed to be Numpy arrays.\n",
    "model.fit(\n",
    "    posts, \n",
    "    [age_targets, income_targets, gender_targets], \n",
    "    epochs=10, \n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Equivalent (possible only if you give names to the output layers)\n",
    "model.fit(\n",
    "    posts, \n",
    "    {'age': age_targets, 'income': income_targets, 'gender': gender_targets},\n",
    "    epochs=10, \n",
    "    batch_size=64\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed acyclic graphs of layers\n",
    "\n",
    "With the functional API, not only can you build models with multiple inputs and multiple outputs, but you can also implement networks with a complex internal topology. Neural networks in _Keras_ are allowed to be arbitrary _directed acyclic graphs_ of layers. The qualifier _acyclic_ is important: **these graphs can’t have cycles**. It’s impossible for a tensor x to become the input of one of the layers that generated x. The only processing loops that are allowed (that is, recurrent connections) are those internal to recurrent layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception modules\n",
    "\n",
    "_Inception_ is a popular type of network architecture for convolutional neural networks; it was developed by _Christian Szegedy_ and his colleagues at Google in 2013–2014, inspired by the earlier network-in-network architecture. It consists of a stack of modules that themselves look like small independent networks, split into several parallel branches. Here's an example, taken from Inception V3:\n",
    "\n",
    "<img src=\"./resources/inception-module.png\" alt=\"qa-model\" style=\"width: 400px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every branch has the same stride value (2), which is necessary to  \n",
    "# keep all branch outputs the same size so you can concatenate them.\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "# In this branch, the striding occurs in the spatial convolution layer.\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "# In this branch, the striding occurs in the average pooling layer.\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "# Concatenates the branch outputs to obtain the module output\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual connections\n",
    "\n",
    "_Residual connections_ are a common graph-like network component found in many post- 2015 network architectures, including _Xception_.\n",
    "A residual connection consists of **making the output of an earlier layer available as input to a later layer**, effectively creating a shortcut in a sequential network. Rather than being concatenated to the later activation, **the earlier output is summed with the later activation**, which **assumes that both activations are the same size**. If they’re different sizes, you can use a linear transformation to reshape the earlier activation into the target shape (for example, a `Dense` layer without an activation or, for convolutional feature maps, a 1 × 1 convolution without an activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here’s how to implement a residual connection in _Keras_ when the feature-map sizes are the same, using identity residual connections. This example assumes the exis- tence of a 4D input tensor `x`:\n",
    "\n",
    "from tensorflow.keras import layers Applies a transformation to x\n",
    "\n",
    "# Applies a transformation to x\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "# Adds the original x back to the output features\n",
    "y = layers.add([y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following implements a residual connection when the feature-map sizes differ, using a linear residual connection (again, assuming the existence of a 4D input tensor `x`)\n",
    "\n",
    "from keras import layers \n",
    "\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# Uses a 1 × 1 convolution to linearly downsample \n",
    "# the original x tensor to the same shape as y\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "\n",
    "# Adds the residual tensor back to the output features\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer weight sharing\n",
    "\n",
    "One more important feature of the functional API is the **ability to reuse a layer instance several times**. When you call a layer instance twice, instead of instantiating a new layer for each call, you reuse the same weights with every call. This allows you to build models that have branches that share the same knowledge and perform the same operations. That is, they share the same representations and learn these representations simultaneously for different sets of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, consider a model that attempts to assess the semantic similarity between two sentences. The model has two inputs (the two sentences to compare) and outputs a score between 0 and 1, where 0 means unrelated sentences and 1 means sentences that are either identical or reformulations of each other.\n",
    "\n",
    "In this setup, the two input sentences are interchangeable, because semantic similarity is a symmetrical relationship: the similarity of A to B is identical to the similarity of B to A. For this reason, it wouldn’t make sense to learn two independent models for processing each input sentence. Rather, you want to process both with a single `LSTM` layer. The representations of this `LSTM` layer (its weights) are learned based on both inputs simultaneously. This is what we call a _Siamese LSTM model_ or a _shared LSTM_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a single LSTM layer, once\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "# Building the left branch of the model: \n",
    "# inputs are variable-length sequences of vectors of size 128.\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "# Building the right branch of the model: \n",
    "# when you call an existing layer instance, you reuse its weights.\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# Builds the classifier on top\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1) \n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# Instantiating and training the model: when you train such a model, \n",
    "# the weights of the LSTM layer are updated based on both inputs.\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models as layers\n",
    "\n",
    "Importantly, in the functional API, models can be used as you’d use layers—effectively, you can think of a model as a “bigger layer.” This is true of both the `Sequential` and `Model` classes.\n",
    "When you call a model instance, **you’re reusing the weights of the model, exactly like what happens when you call a layer instance**. Calling an instance, whether it’s a layer instance or a model instance, will always **reuse the existing learned representations of the instance**, which is intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple practical example of what you can build by reusing a model instance is a vision model that uses a dual camera as its input: two parallel cameras, a few centimeters (one inch) apart. \n",
    "Such a model can perceive depth, which can be useful in many applications. \n",
    "\n",
    "**You shouldn’t need two independent models** to extract visual features from the left camera and the right camera before merging the two feeds. Such low-level processing can be shared across the two inputs: that is, done via layers that use the same weights and thus share the same representations. Here's how you'd implement a Siamese vision model (shared convolutional base) in _Keras_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# The base image-processing model is the Xception network (convolutional base only).\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "# The inputs are 250 × 250 RGB images.\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "# Calls the same vision model twice\n",
    "left_features = xception_base(left_input)\n",
    "right_input = xception_base(right_input)\n",
    "\n",
    "# The merged features contain information from the right visual feed and the left visual feed.\n",
    "merged_features = layers.concatenate([left_features, right_input], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
